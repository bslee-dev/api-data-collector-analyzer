"""
ë°ì´í„° ë¶„ì„ê¸°
ìˆ˜ì§‘ëœ ë°ì´í„°ì— ëŒ€í•œ í†µê³„ ë° íŠ¸ë Œë“œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from collections import Counter
import re


class DataAnalyzer:
    """ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.results = {}
    
    def analyze(self, data, source=None):
        """
        ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
        
        Args:
            data: ë¶„ì„í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            source: ë°ì´í„° ì†ŒìŠ¤ (reddit, github, hackernews)
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not data:
            return {}
        
        # ì†ŒìŠ¤ ìë™ ê°ì§€
        if source is None:
            source = data[0].get('source', 'unknown') if data else 'unknown'
        
        print(f"ğŸ“Š ë°ì´í„° ë¶„ì„ ì¤‘: {source}")
        
        df = pd.DataFrame(data)
        results = {
            'source': source,
            'total_count': len(data),
            'timestamp': datetime.now().isoformat()
        }
        
        # ì†ŒìŠ¤ë³„ ë¶„ì„
        if source == 'reddit':
            results.update(self._analyze_reddit(df))
        elif source == 'github':
            results.update(self._analyze_github(df))
        elif source == 'hackernews':
            results.update(self._analyze_hackernews(df))
        
        self.results = results
        return results
    
    def _analyze_reddit(self, df):
        """Reddit ë°ì´í„° ë¶„ì„"""
        analysis = {}
        
        # ê¸°ë³¸ í†µê³„
        if 'score' in df.columns:
            analysis['score_stats'] = {
                'mean': float(df['score'].mean()),
                'median': float(df['score'].median()),
                'std': float(df['score'].std()),
                'max': int(df['score'].max()),
                'min': int(df['score'].min())
            }
        
        if 'num_comments' in df.columns:
            analysis['comments_stats'] = {
                'mean': float(df['num_comments'].mean()),
                'median': float(df['num_comments'].median()),
                'max': int(df['num_comments'].max())
            }
        
        # ì„œë¸Œë ˆë”§ë³„ í†µê³„
        if 'subreddit' in df.columns:
            subreddit_counts = df['subreddit'].value_counts().to_dict()
            analysis['subreddit_distribution'] = subreddit_counts
        
        # í‚¤ì›Œë“œ ë¶„ì„
        if 'title' in df.columns:
            analysis['top_keywords'] = self._extract_keywords(df['title'].tolist())
        
        return analysis
    
    def _analyze_github(self, df):
        """GitHub ë°ì´í„° ë¶„ì„"""
        analysis = {}
        
        # ê¸°ë³¸ í†µê³„
        if 'stars' in df.columns:
            analysis['stars_stats'] = {
                'mean': float(df['stars'].mean()),
                'median': float(df['stars'].median()),
                'std': float(df['stars'].std()),
                'max': int(df['stars'].max())
            }
        
        if 'forks' in df.columns:
            analysis['forks_stats'] = {
                'mean': float(df['forks'].mean()),
                'median': float(df['forks'].median()),
                'max': int(df['forks'].max())
            }
        
        # ì–¸ì–´ë³„ í†µê³„
        if 'language' in df.columns:
            language_counts = df['language'].value_counts().to_dict()
            analysis['language_distribution'] = language_counts
        
        # ë¼ì´ì„ ìŠ¤ ë¶„í¬
        if 'license' in df.columns:
            license_counts = df['license'].value_counts().to_dict()
            analysis['license_distribution'] = license_counts
        
        # í† í”½ ë¶„ì„
        if 'topics' in df.columns:
            all_topics = []
            for topics in df['topics'].dropna():
                if isinstance(topics, list):
                    all_topics.extend(topics)
            if all_topics:
                topic_counts = Counter(all_topics)
                analysis['top_topics'] = dict(topic_counts.most_common(20))
        
        return analysis
    
    def _analyze_hackernews(self, df):
        """HackerNews ë°ì´í„° ë¶„ì„"""
        analysis = {}
        
        # ê¸°ë³¸ í†µê³„
        if 'score' in df.columns:
            analysis['score_stats'] = {
                'mean': float(df['score'].mean()),
                'median': float(df['score'].median()),
                'std': float(df['score'].std()),
                'max': int(df['score'].max())
            }
        
        if 'descendants' in df.columns:
            analysis['comments_stats'] = {
                'mean': float(df['descendants'].mean()),
                'median': float(df['descendants'].median()),
                'max': int(df['descendants'].max())
            }
        
        # í‚¤ì›Œë“œ ë¶„ì„
        if 'title' in df.columns:
            analysis['top_keywords'] = self._extract_keywords(df['title'].tolist())
        
        return analysis
    
    def _extract_keywords(self, texts, top_n=20):
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ ë‹¨ì–´)
        all_words = []
        for text in texts:
            if text:
                # ì†Œë¬¸ì ë³€í™˜ ë° ë‹¨ì–´ ì¶”ì¶œ
                words = re.findall(r'\b[a-zA-Z]{2,}\b', text.lower())
                all_words.extend(words)
        
        # ë¶ˆìš©ì–´ ì œê±° (ê°„ë‹¨í•œ ë²„ì „)
        stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'should', 'could', 'may', 'might', 'this', 'that', 'these', 'those', 'from', 'as', 'it', 'its', 'they', 'them', 'their', 'what', 'which', 'who', 'when', 'where', 'why', 'how'}
        filtered_words = [w for w in all_words if w not in stopwords and len(w) > 2]
        
        word_counts = Counter(filtered_words)
        return dict(word_counts.most_common(top_n))
    
    def save_results(self, results=None, filename=None):
        """ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if results is None:
            results = self.results
        
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            source = results.get('source', 'unknown')
            filename = f"analysis_{source}_{timestamp}.json"
        
        filepath = Path('outputs') / filename
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {filepath}")
        return filepath

