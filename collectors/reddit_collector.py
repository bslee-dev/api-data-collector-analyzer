"""
Reddit ë°ì´í„° ìˆ˜ì§‘ê¸°
Reddit APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²Œì‹œë¬¼ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

import requests
import json
import time
from datetime import datetime
from pathlib import Path
import config


class RedditCollector:
    """Redditì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.base_url = "https://www.reddit.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'DataAnalyticsEngineer/1.0 (Educational Project)'
        })
    
    def collect(self, subreddit='python', limit=100, sort='hot'):
        """
        Redditì—ì„œ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            subreddit: ì„œë¸Œë ˆë”§ ì´ë¦„
            limit: ìˆ˜ì§‘í•  ê²Œì‹œë¬¼ ìˆ˜
            sort: ì •ë ¬ ë°©ì‹ (hot, new, top, rising)
        
        Returns:
            ìˆ˜ì§‘ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ” Redditì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘: r/{subreddit} ({sort})")
        
        url = f"{self.base_url}/r/{subreddit}/{sort}.json"
        params = {'limit': min(limit, 100)}
        
        all_posts = []
        after = None
        
        while len(all_posts) < limit:
            if after:
                params['after'] = after
            
            try:
                response = self.session.get(url, params=params, timeout=10)
                response.raise_for_status()
                data = response.json()
                
                posts = data.get('data', {}).get('children', [])
                
                for post in posts:
                    post_data = post.get('data', {})
                    all_posts.append({
                        'id': post_data.get('id'),
                        'title': post_data.get('title'),
                        'author': post_data.get('author'),
                        'score': post_data.get('score', 0),
                        'upvote_ratio': post_data.get('upvote_ratio', 0),
                        'num_comments': post_data.get('num_comments', 0),
                        'created_utc': post_data.get('created_utc'),
                        'url': post_data.get('url'),
                        'permalink': f"https://reddit.com{post_data.get('permalink', '')}",
                        'subreddit': post_data.get('subreddit'),
                        'selftext': post_data.get('selftext', '')[:500],  # ì²˜ìŒ 500ìë§Œ
                        'source': 'reddit'
                    })
                    
                    if len(all_posts) >= limit:
                        break
                
                after = data.get('data', {}).get('after')
                if not after:
                    break
                
                # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
                time.sleep(1)
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ Reddit ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                break
        
        print(f"âœ… {len(all_posts)}ê°œì˜ Reddit ê²Œì‹œë¬¼ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_posts[:limit]
    
    def save(self, data, filename=None):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"reddit_{timestamp}.json"
        
        filepath = Path(config.RAW_DATA_DIR) / filename
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ë°ì´í„° ì €ì¥: {filepath}")
        return filepath

