"""
API Data Collector & Analyzer
ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import argparse
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from collectors import RedditCollector, GitHubCollector, HackerNewsCollector
from analyzers import DataAnalyzer, Visualizer
from database import DatabaseManager
from scheduler import TaskScheduler
from scheduler.task_scheduler import create_collection_job_wrapper
import config
import time
import signal


def collect_reddit(limit=None, db_manager=None):
    """Reddit ë°ì´í„° ìˆ˜ì§‘"""
    collector = RedditCollector()
    limit = limit or config.DEFAULT_LIMIT
    data = collector.collect(subreddit=config.REDDIT_SUBREDDIT, limit=limit)
    if data:
        collector.save(data)
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        if config.ENABLE_DATABASE and db_manager:
            db_manager.save_collection(data, 'reddit')
    return data


def collect_github(limit=None, db_manager=None):
    """GitHub ë°ì´í„° ìˆ˜ì§‘"""
    collector = GitHubCollector()
    limit = limit or config.DEFAULT_LIMIT
    data = collector.collect(language=config.GITHUB_LANGUAGE, limit=limit)
    if data:
        collector.save(data)
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        if config.ENABLE_DATABASE and db_manager:
            db_manager.save_collection(data, 'github')
    return data


def collect_hackernews(limit=None, db_manager=None):
    """HackerNews ë°ì´í„° ìˆ˜ì§‘"""
    collector = HackerNewsCollector()
    limit = limit or config.HACKERNEWS_LIMIT
    data = collector.collect(limit=limit)
    if data:
        collector.save(data)
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        if config.ENABLE_DATABASE and db_manager:
            db_manager.save_collection(data, 'hackernews')
    return data


def analyze_data(data, source):
    """ë°ì´í„° ë¶„ì„"""
    analyzer = DataAnalyzer()
    results = analyzer.analyze(data, source=source)
    analyzer.save_results(results)
    return results


def visualize_data(data, source):
    """ë°ì´í„° ì‹œê°í™”"""
    visualizer = Visualizer()
    visualizer.visualize(data, source=source)


def main():
    parser = argparse.ArgumentParser(
        description='API Data Collector & Analyzer',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python main.py                    # ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„
  python main.py --source reddit    # Redditë§Œ ìˆ˜ì§‘
  python main.py --source github    # GitHubë§Œ ìˆ˜ì§‘
  python main.py --analyze-only     # ì´ë¯¸ ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„ë§Œ ìˆ˜í–‰
        """
    )
    
    parser.add_argument(
        '--source',
        choices=['reddit', 'github', 'hackernews', 'all'],
        default='all',
        help='ìˆ˜ì§‘í•  ë°ì´í„° ì†ŒìŠ¤ (ê¸°ë³¸ê°’: all)'
    )
    
    parser.add_argument(
        '--limit',
        type=int,
        default=config.DEFAULT_LIMIT,
        help=f'ìˆ˜ì§‘í•  ë°ì´í„° ìˆ˜ (ê¸°ë³¸ê°’: {config.DEFAULT_LIMIT})'
    )
    
    parser.add_argument(
        '--analyze-only',
        action='store_true',
        help='ë°ì´í„° ìˆ˜ì§‘ ì—†ì´ ë¶„ì„ë§Œ ìˆ˜í–‰ (ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©)'
    )
    
    parser.add_argument(
        '--no-visualize',
        action='store_true',
        help='ì‹œê°í™” ìƒëµ'
    )
    
    parser.add_argument(
        '--compare',
        action='store_true',
        help='ì´ì „ ë°ì´í„°ì™€ ë¹„êµ ë¶„ì„ ìˆ˜í–‰'
    )
    
    parser.add_argument(
        '--db-stats',
        action='store_true',
        help='ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ'
    )
    
    parser.add_argument(
        '--schedule',
        action='store_true',
        help='ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“œë¡œ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì£¼ê¸°ì  ìˆ˜ì§‘)'
    )
    
    parser.add_argument(
        '--schedule-daily',
        type=str,
        metavar='HH:MM',
        help='ë§¤ì¼ íŠ¹ì • ì‹œê°„ì— ì‹¤í–‰ (ì˜ˆ: --schedule-daily 09:00)'
    )
    
    parser.add_argument(
        '--schedule-interval',
        type=int,
        metavar='HOURS',
        help='Nì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ (ì˜ˆ: --schedule-interval 6)'
    )
    
    parser.add_argument(
        '--max-retries',
        type=int,
        default=3,
        help='ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3)'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ” API Data Collector & Analyzer")
    print("=" * 60)
    print()
    
    # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì ì´ˆê¸°í™”
    db_manager = None
    if config.ENABLE_DATABASE:
        try:
            db_manager = DatabaseManager()
        except Exception as e:
            print(f"âš ï¸  ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("   JSON íŒŒì¼ ì €ì¥ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ
    if args.db_stats:
        if db_manager:
            stats = db_manager.get_statistics()
            print("\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
            print("=" * 60)
            print(f"ì†ŒìŠ¤ë³„ ì„¸ì…˜ ìˆ˜:")
            for source, count in stats.get('sessions_by_source', {}).items():
                print(f"  {source}: {count}ê°œ")
            print(f"\nì´ ë°ì´í„° ìˆ˜:")
            print(f"  Reddit ê²Œì‹œë¬¼: {stats.get('total_reddit_posts', 0)}ê°œ")
            print(f"  GitHub ì €ì¥ì†Œ: {stats.get('total_github_repos', 0)}ê°œ")
            print(f"  HackerNews ìŠ¤í† ë¦¬: {stats.get('total_hackernews_stories', 0)}ê°œ")
            print(f"\nìµœì‹  ìˆ˜ì§‘ ì‹œê°„:")
            for source, last_time in stats.get('last_collected', {}).items():
                print(f"  {source}: {last_time}")
        else:
            print("âŒ ë°ì´í„°ë² ì´ìŠ¤ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“œ
    if args.schedule or args.schedule_daily or args.schedule_interval:
        return run_scheduler_mode(args, db_manager)
    
    if args.analyze_only:
        print("ğŸ“Š ë¶„ì„ ëª¨ë“œ: ê¸°ì¡´ ë°ì´í„° ë¶„ì„")
        # TODO: ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
        print("âš ï¸  ë¶„ì„ ëª¨ë“œëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ìˆ˜ì§‘
    sources_to_collect = []
    if args.source == 'all':
        sources_to_collect = ['reddit', 'github', 'hackernews']
    else:
        sources_to_collect = [args.source]
    
    all_data = {}
    
    for source in sources_to_collect:
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ {source.upper()} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"{'='*60}\n")
        
        try:
            if source == 'reddit':
                data = collect_reddit(args.limit, db_manager)
            elif source == 'github':
                data = collect_github(args.limit, db_manager)
            elif source == 'hackernews':
                data = collect_hackernews(args.limit, db_manager)
            else:
                continue
            
            if data:
                all_data[source] = data
                
                # ì´ì „ ë°ì´í„°ì™€ ë¹„êµ
                if args.compare and db_manager:
                    print(f"\n{'='*60}")
                    print(f"ğŸ” {source.upper()} ì´ì „ ë°ì´í„°ì™€ ë¹„êµ")
                    print(f"{'='*60}\n")
                    latest_session = db_manager.get_latest_session(source)
                    if latest_session:
                        sessions = db_manager.get_recent_sessions(source, limit=2)
                        if len(sessions) >= 2:
                            comparison = db_manager.compare_sessions(
                                source, sessions[1]['id'], sessions[0]['id']
                            )
                            print(f"ì„¸ì…˜ ë¹„êµ ê²°ê³¼:")
                            print(f"  ì´ì „ ì„¸ì…˜: {sessions[1]['collected_at']} ({sessions[1]['item_count']}ê°œ)")
                            print(f"  í˜„ì¬ ì„¸ì…˜: {sessions[0]['collected_at']} ({sessions[0]['item_count']}ê°œ)")
                            print(f"  ë°ì´í„° ìˆ˜ ë³€í™”: {comparison.get('count_change', 0)}ê°œ ({comparison.get('count_change_percent', 0):.2f}%)")
                            
                            if source == 'reddit' and 'score' in comparison:
                                score_info = comparison['score']
                                print(f"  í‰ê·  ì ìˆ˜ ë³€í™”: {score_info.get('change', 0):.2f} ({score_info.get('change_percent', 0):.2f}%)")
                            elif source == 'github' and 'stars' in comparison:
                                stars_info = comparison['stars']
                                print(f"  í‰ê·  ìŠ¤íƒ€ ìˆ˜ ë³€í™”: {stars_info.get('change', 0):.2f} ({stars_info.get('change_percent', 0):.2f}%)")
                            elif source == 'hackernews' and 'score' in comparison:
                                score_info = comparison['score']
                                print(f"  í‰ê·  ì ìˆ˜ ë³€í™”: {score_info.get('change', 0):.2f} ({score_info.get('change_percent', 0):.2f}%)")
                
                # ë¶„ì„
                print(f"\n{'='*60}")
                print(f"ğŸ“Š {source.upper()} ë°ì´í„° ë¶„ì„")
                print(f"{'='*60}\n")
                results = analyze_data(data, source)
                
                # ì‹œê°í™”
                if not args.no_visualize:
                    print(f"\n{'='*60}")
                    print(f"ğŸ“ˆ {source.upper()} ë°ì´í„° ì‹œê°í™”")
                    print(f"{'='*60}\n")
                    visualize_data(data, source)
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ {source} ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ìš”ì•½
    print(f"\n{'='*60}")
    print("âœ… ì‘ì—… ì™„ë£Œ ìš”ì•½")
    print(f"{'='*60}")
    for source, data in all_data.items():
        print(f"  {source}: {len(data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ")
    print(f"\nğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜:")
    print(f"  - ì›ë³¸ ë°ì´í„°: {config.RAW_DATA_DIR}")
    print(f"  - ë¶„ì„ ê²°ê³¼: outputs/")
    print(f"  - ì‹œê°í™”: outputs/")
    if config.ENABLE_DATABASE and db_manager:
        print(f"  - ë°ì´í„°ë² ì´ìŠ¤: {config.DB_PATH}")


def run_scheduler_mode(args, db_manager):
    """ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“œ ì‹¤í–‰"""
    print("â° ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“œ ì‹œì‘")
    print("=" * 60)
    print("Ctrl+Cë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("=" * 60)
    print()
    
    scheduler = TaskScheduler(max_retries=args.max_retries)
    
    # ìˆ˜ì§‘ í•¨ìˆ˜ ë˜í¼ ìƒì„±
    def collect_with_analysis(source, limit):
        """ìˆ˜ì§‘ ë° ë¶„ì„ì„ í•¨ê»˜ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
        try:
            if source == 'reddit':
                data = collect_reddit(limit, db_manager)
            elif source == 'github':
                data = collect_github(limit, db_manager)
            elif source == 'hackernews':
                data = collect_hackernews(limit, db_manager)
            else:
                return
            
            if data:
                # ë¶„ì„ ìˆ˜í–‰
                analyze_data(data, source)
        except Exception as e:
            print(f"âŒ {source} ìˆ˜ì§‘/ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    # ìŠ¤ì¼€ì¤„ ì„¤ì •
    sources_to_schedule = []
    if args.source == 'all':
        sources_to_schedule = ['reddit', 'github', 'hackernews']
    else:
        sources_to_schedule = [args.source]
    
    if args.schedule_daily:
        # ë§¤ì¼ íŠ¹ì • ì‹œê°„ì— ì‹¤í–‰
        try:
            hour, minute = map(int, args.schedule_daily.split(':'))
            print(f"ğŸ“… ë§¤ì¼ {hour:02d}:{minute:02d}ì— ì‹¤í–‰ë˜ë„ë¡ ìŠ¤ì¼€ì¤„ ì„¤ì •")
            for source in sources_to_schedule:
                job_func = lambda s=source: collect_with_analysis(s, args.limit)
                scheduler.add_daily_job(
                    job_func,
                    hour=hour,
                    minute=minute,
                    job_id=f"daily_{source}"
                )
        except ValueError:
            print("âŒ ì‹œê°„ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. HH:MM í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.")
            return
    
    elif args.schedule_interval:
        # ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
        print(f"â±ï¸  {args.schedule_interval}ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ë˜ë„ë¡ ìŠ¤ì¼€ì¤„ ì„¤ì •")
        for source in sources_to_schedule:
            job_func = lambda s=source: collect_with_analysis(s, args.limit)
            scheduler.add_interval_job(
                job_func,
                hours=args.schedule_interval,
                job_id=f"interval_{source}"
            )
    
    else:
        # ê¸°ë³¸: ë§¤ì¼ ìì •ì— ì‹¤í–‰
        print("ğŸ“… ë§¤ì¼ 00:00ì— ì‹¤í–‰ë˜ë„ë¡ ìŠ¤ì¼€ì¤„ ì„¤ì • (ê¸°ë³¸ê°’)")
        for source in sources_to_schedule:
            job_func = lambda s=source: collect_with_analysis(s, args.limit)
            scheduler.add_daily_job(
                job_func,
                hour=0,
                minute=0,
                job_id=f"daily_{source}"
            )
    
    # ë“±ë¡ëœ ì‘ì—… ëª©ë¡ ì¶œë ¥
    jobs = scheduler.get_jobs()
    print(f"\nâœ… {len(jobs)}ê°œì˜ ì‘ì—…ì´ ìŠ¤ì¼€ì¤„ì— ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤:")
    for job in jobs:
        print(f"  - {job.id}: {job.next_run_time}")
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    scheduler.start()
    
    # ì¢…ë£Œ ì‹ í˜¸ ì²˜ë¦¬
    def signal_handler(sig, frame):
        print("\n\nâ¹ï¸  ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì¤‘...")
        scheduler.stop()
        print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
    print("\nğŸ”„ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤...")
    print("   ë¡œê·¸ëŠ” scheduler.log íŒŒì¼ì— ê¸°ë¡ë©ë‹ˆë‹¤.\n")
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        signal_handler(None, None)


if __name__ == '__main__':
    main()

